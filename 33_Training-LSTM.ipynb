{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69e87f3-ec1f-4cea-91b6-8486c28e9fa2",
   "metadata": {},
   "source": [
    "CNNs on ECG Images: CNNs are highly effective for extracting spatial features from ECG images, leading to high classification accuracy.\n",
    "Hybrid Models: Combining CNNs with RNNs or LSTMs can capture both spatial and temporal features, potentially improving performance further.\n",
    "Data Preprocessing: Effective preprocessing steps enhance important features and contribute to model performance.\n",
    "This combination of techniques and considerations helps explain why MobileNetV2 performed well on your ECG dataset despite ECG being inherently time-series data. If you have any further questions or need more details, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee261bf6-80eb-49a1-b0d2-7301b00b03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b0db96-bd19-4585-8f55-e9374ad9131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN-LSTM hybrid model\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(64 * 28 * 28, 128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
    "        c_out = self.cnn(c_in)\n",
    "        r_in = c_out.view(batch_size, timesteps, -1)\n",
    "        r_out, (h_n, c_n) = self.lstm(r_in)\n",
    "        out = self.fc(r_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "data_dir = 'E:/PPInput'\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNLSTM(num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training and evaluation loop\n",
    "def train_and_evaluate(model, train_loader, val_loader, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.unsqueeze(1)  # Add a dummy time dimension\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.unsqueeze(1)  # Add a dummy time dimension\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "    recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a469bf64-5b63-48ed-89a0-0c904fe0f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9932, Precision: 0.9934, Recall: 0.9932, F1 Score: 0.9932\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "accuracy, precision, recall, f1 = train_and_evaluate(model, train_loader, val_loader)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3beeb11-aa33-4200-bdd9-e1b05cb68a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = 'Prac'\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
